import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq

# 文件路径
data_file = 'your_large_file.csv'     # 主CSV文件，无header
header_file = 'header.csv'            # 包含一行列名
parquet_file = 'output_7m.parquet'

# 参数设置
chunk_size = 100_000
target_rows = 7_000_000
rows_written = 0

# 读取列名
column_names = pd.read_csv(header_file, header=None).iloc[0].tolist()

# 初始化Parquet写入器（使用pyarrow）
parquet_writer = None

# 按块读取CSV并逐块写入Parquet
for chunk in pd.read_csv(data_file, header=None, names=column_names, chunksize=chunk_size):
    if rows_written >= target_rows:
        break

    # 如果最后一个chunk超过了剩余的目标行数，则裁剪
    if rows_written + len(chunk) > target_rows:
        chunk = chunk.iloc[:target_rows - rows_written]

    # 转换为 Arrow 表格
    table = pa.Table.from_pandas(chunk)

    # 初始化写入器
    if parquet_writer is None:
        parquet_writer = pq.ParquetWriter(parquet_file, table.schema)

    parquet_writer.write_table(table)
    rows_written += len(chunk)

# 关闭写入器
if parquet_writer:
    parquet_writer.close()

import pandas as pd
import numpy as np

def process_data(data_path, header_path):
    """
    处理无表头的 data.csv 和带有信息的 header.csv：
    - 加上表头
    - 用 header 第三行补全缺失值
    - 根据 header 第一行调整数据类型
    
    Args:
        data_path (str): data.csv 的路径
        header_path (str): header.csv 的路径
        
    Returns:
        pd.DataFrame: 处理后的 DataFrame
    """
    # 读取 header.csv
    header_df = pd.read_csv(header_path, header=None)

    # 获取列名、数据类型、缺失值填充值
    dtypes_row = header_df.iloc[0]   # 第一行，数据类型 N/C/I/L
    col_names = header_df.iloc[1]   # 第二行，列名
    fill_values = header_df.iloc[2] # 第三行，用来填补空值
    
    # 读取 data.csv，没有表头
    data_df = pd.read_csv(data_path, header=None)
    
    # 设置表头
    data_df.columns = col_names
    
    # 填补缺失值
    for col in data_df.columns:
        data_df[col] = data_df[col].replace(['', ' ', 'NaN', 'nan', np.nan], np.nan)
        if pd.isna(fill_values[col]):
            continue
        data_df[col] = data_df[col].fillna(fill_values[col])
    
    # 转换数据类型
    for col in data_df.columns:
        dtype_code = dtypes_row[col]
        if dtype_code == 'N':
            data_df[col] = pd.to_numeric(data_df[col], errors='coerce')
        elif dtype_code in ['I', 'L']:
            data_df[col] = pd.to_numeric(data_df[col], errors='coerce').astype('Int64')
        elif dtype_code == 'C':
            data_df[col] = data_df[col].astype('category')
    
    return data_df



import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from tensorflow import keras
from tensorflow.keras import layers
import keras_tuner as kt

# 设定输入数据（举例，请用你自己的数据替换）
# X, y = ... 
# X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(...)

input_dim = X_train_scaled.shape[1]

def build_ann_model(hp):
    model = keras.Sequential()
    # 第一层
    model.add(layers.Dense(
        units=hp.Int('units1', min_value=32, max_value=128, step=32),
        activation='relu',
        input_shape=(input_dim,)
    ))
    model.add(layers.Dropout(hp.Float('dropout1', 0.0, 0.5, step=0.1)))
    # 第二层
    model.add(layers.Dense(
        units=hp.Int('units2', min_value=8, max_value=64, step=8),
        activation='relu'
    ))
    model.add(layers.Dropout(hp.Float('dropout2', 0.0, 0.5, step=0.1)))
    # 输出层
    model.add(layers.Dense(1, activation='sigmoid'))
    # 优化器和学习率
    model.compile(
        optimizer=keras.optimizers.Adam(
            hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),
        loss='binary_crossentropy',
        metrics=['AUC']
    )
    return model

# 定义调参器
tuner = kt.RandomSearch(
    build_ann_model,
    objective='val_auc',   # 用AUC作为评价指标
    max_trials=10,         # 尝试10组参数组合
    executions_per_trial=1,
    directory='ann_tuning_dir',  # 保存模型的文件夹
    project_name='ann_hyperparam'
)

# 启动调参
tuner.search(
    X_train_scaled, y_train,
    epochs=50,                 # 每组最多训练50轮
    validation_split=0.2,
    batch_size=64,
    callbacks=[keras.callbacks.EarlyStopping(patience=5)],
    verbose=2
)

# 获取最优模型
best_model = tuner.get_best_models(num_models=1)[0]

# 用最优模型预测
y_pred = best_model.predict(X_test_scaled).flatten()
auc = roc_auc_score(y_test, y_pred)
print(f'Best ANN AUC: {auc:.4f}')

# 查看最佳超参数
best_hp = tuner.get_best_hyperparameters()[0]
print('Best Hyperparameters:')
for key in best_hp.values.keys():
    print(f'  {key}: {best_hp.get(key)}')
